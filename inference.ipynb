{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90108aed-52b7-43c9-b430-5d4e6fd76f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "path = '/home/ubuntu/llama-7b-fine-tune-jokes-2'\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ac793-2dfd-4e77-af23-0472c4a4561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    path,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {\n",
    "        \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "        \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "        \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf65550-f1ec-4fc6-866a-abeb218b8b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e211868-201f-40d6-9e0a-37ffa254606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_template = (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\")\n",
    "\n",
    "instruction = { 'instruction' : \"Write a joke\" }\n",
    "\n",
    "prompt = instruction_template.format_map(instruction)\n",
    "\n",
    "def generate_from_prompt(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate\n",
    "    generate_ids = model.generate(inputs.input_ids, max_length=500, eos_token_id=tokenizer.eos_token_id)\n",
    "    res = tokenizer.batch_decode(generate_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return res\n",
    "\n",
    "res = generate_from_prompt(prompt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1bee3d-9aab-485d-979b-12bbb431269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = res\n",
    "\n",
    "instruction = { 'instruction' : \"Write a another joke\" }\n",
    "\n",
    "prompt = f'{start} \\n\\n {instruction_template.format_map(instruction)}'\n",
    "\n",
    "res = generate_from_prompt(prompt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f843d6-51c5-4457-b350-e491253830a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
